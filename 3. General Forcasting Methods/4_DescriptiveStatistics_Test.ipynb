{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_DescriptiveStatistics_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlyL0SIx1wzJ4uzdyd8GkX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/worklifesg/Time-Series-Forecasting-and-Analysis/blob/main/3.%20General%20Forcasting%20Methods/4_DescriptiveStatistics_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctazvNOibZZb"
      },
      "source": [
        "<h3> General Forecasting Methods </h3>\n",
        "\n",
        "<b> Forecasting Procedure: </b> \n",
        "\n",
        " - Choose Model (through statistical analysis)\n",
        " - Split data into train and test sets (for fairly evaluate our model)\n",
        " - Fit model on training set\n",
        " - Evaluate model on test set\n",
        " - Refit model on etire dataset\n",
        " - Forecast for future dataset\n",
        "\n",
        "<b> Section Overview: </b> \n",
        "\n",
        " - Forecasting\n",
        " - ACF and PACF plots\n",
        " - Autoregression - AR\n",
        " - Descriptive Statistics and Tests\n",
        " - Choosing ARIMA orders\n",
        " - ARIMA based models\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKDiOfi_biL4"
      },
      "source": [
        "#### Descriptive Tests - Part 1\n",
        "\n",
        "In this work, we will use statsmodels to explore underlying attributes of a time series. Different tests:\n",
        "\n",
        "- <b> Tests for Stationarity </b>\n",
        "\n",
        " a) Augmented Dickey-Fuller Test --> determine whether a series is stationary\n",
        " - It means to have a <b> null hypothesis test </b> and returns a <b> p </b> value\n",
        " - <b> Null hypothesis test </b> states $\\phi=1$ - unit test\n",
        " - if p is low $(p<0.05)$, we reject this null hypothesis test, so we can assume the dataset is stationary <b> (Your results are statistically significant.) </b>\n",
        " - if p is high $(p>0.05)$, we fail to reject null hypothesis test <b> (Your results are not statistically significant.) </b>\n",
        " - To understand why we don’t accept the null, consider the fact that you can’t prove a negative. \n",
        "\n",
        "- <b> Granger Causality Tests </b>\n",
        " - Hypothesis test to determine if one of the time series is useful in forecasting another else cause causality.\n",
        " - It is important to observe correlation between series (observe changes in one series correlated to changes in another after a consistent amount of time).\n",
        " - It is important to check causality as we might have outside factor unaccounted for !\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqUQnRR4hEUN"
      },
      "source": [
        "##### <b> Information Criterion </b>\n",
        "\n",
        "Basically we will see 2 types of IC:\n",
        "- AIC (Akaike Information Criterion)\n",
        "- BIC (Bayesian Information Criterion)\n",
        "\n",
        "<i> <u> AIC (Akaike Information Criterion) </u> </i>\n",
        "\n",
        " - Developed by Hirotugu Akaike in 1971\n",
        " - Evaluates collection of models and estimates quality of each model relative to the others.\n",
        " - Penalties are provided for the number of parameters used in an effort to avoid overfitting.\n",
        " - Example ~ if we have extremely complex model whose performance is minor better than simple model then AIC suggest to choose simple model overlooking complexities in the model.\n",
        "\n",
        "<i> <u> BIC (Bayesian Information Criterion) </u> </i>.\n",
        "\n",
        " - Similar to AIC but mathematics behing BIC model has <b> Bayesian approach </b>\n",
        " - Developed by Gidean Schwarz in 1978.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEyH9YUNbf2A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}